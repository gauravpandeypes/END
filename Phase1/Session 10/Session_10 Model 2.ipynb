{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "model2.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StuZqZ-Xr8r6",
        "outputId": "177ef9bf-5877-42a7-81c6-ac0b296d6041"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jan 14 22:38:23 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TG71kv7sFLF"
      },
      "source": [
        "# !python -m spacy download de_core_news_sm\r\n",
        "# !pip install torchtext==0.6.0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eygmVxl2r5gk"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import spacy \n",
        "import numpy as np \n",
        "import time"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2h1ydn0r5gs"
      },
      "source": [
        "SEED = 1234\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1wk0FuYr5gt"
      },
      "source": [
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "spacy_de = spacy.load('de_core_news_sm')\n",
        "\n",
        "def tokenize_de(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z1RqlEPr5gt",
        "outputId": "d73786a9-268b-4a15-cd20-fb4c77ca7931"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_en,\n",
        "            init_token='<sos>',\n",
        "            eos_token='<eos>',\n",
        "            lower=True, include_lengths=True)\n",
        "\n",
        "TRG = Field(tokenize=tokenize_de,\n",
        "            init_token='<sos>',\n",
        "            eos_token='<eos>',\n",
        "            lower=True)\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts=('.en', '.de'), fields=(SRC, TRG))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 950kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 272kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 266kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_Kx91JUr5gu"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "SRC.build_vocab(train_data, min_freq=2)\n",
        "TRG.build_vocab(train_data, min_freq=2)\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE, device='cuda', sort_within_batch=True, sort_key=lambda x: len(x.src)\n",
        ")\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev4LCaVQr5gu"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "        \n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "        \n",
        "        #src : [src_len, batch_size]\n",
        "        #src_len : [batch_size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded : [src_len, batch_size, emb_dim]\n",
        "                \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.cpu())\n",
        "                \n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "                                 \n",
        "        #packed_outputs is a packed sequence containing all hidden states\n",
        "        #hidden is now from the final non-padded element in the batch\n",
        "            \n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "        \n",
        "        \n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        #outputs : [src_len, batch_size, enc_hid_dim * 2]\n",
        "        #hidden : [batch_size, dec_hid_dim]\n",
        "        \n",
        "        return outputs, hidden\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        #hidden : [batch_size, dec_hid_dim]\n",
        "        #encoder_outputs : [src_len, batch_size, enc_hid_dim * 2]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        #repeat decoder hidden state src_len times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "  \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #hidden : [batch_size, src_len, dec_hid_dim]\n",
        "        #encoder_outputs : [batch_size, src_len, enc_hid_dim * 2]\n",
        "        \n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
        "        \n",
        "        #energy : [batch_size, src_len, dec_hid_dim]\n",
        "\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        \n",
        "        #attention : [batch_size, src_len]\n",
        "        \n",
        "        attention = attention.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        return F.softmax(attention, dim = 1)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        \n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs, mask):\n",
        "             \n",
        "        #input : [batch_size]\n",
        "        #hidden : [batch_size, dec_hid_dim]\n",
        "        #encoder_outputs : [src_len, batch_size, enc_hid_dim * 2]\n",
        "        #mask : [batch_size, src_len]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input : [1, batch_size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded : [1, batch_size, emb_dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "                \n",
        "        #a : [batch_size, src_len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        \n",
        "        #a : [batch_size, 1, src_len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #encoder_outputs : [batch_size, src_len, enc_hid_dim * 2]\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        \n",
        "        #weighted : [batch_size, 1, enc_hid_dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        \n",
        "        #weighted : [1, batch_size, enc_hid_dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        \n",
        "        #rnn_input : [1, batch_size, (enc_hid_dim * 2) + emb_dim]\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        #output : [seq_len, batch_size, dec_hid_dim * n directions]\n",
        "        #hidden : [n_layers * n directions, batch_size, dec_hid_dim]\n",
        "        \n",
        "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output : [1, batch_size, dec_hid_dim]\n",
        "        #hidden : [1, batch_size, dec_hid_dim]\n",
        "\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkYMB3ylr5gv"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def create_mask(self, src):\n",
        "        mask = (src != self.src_pad_idx).permute(1, 0)\n",
        "        return mask\n",
        "        \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src : [src_len, batch_size]\n",
        "        #src_len : [batch_size]\n",
        "        #trg : [trg_len, batch_size]\n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        mask = self.create_mask(src)\n",
        "\n",
        "        #mask = [batch_size, src_len]\n",
        "                \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
        "            \n",
        "            outputs[t] = output\n",
        "            \n",
        "            teacher_force = np.random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTiBaUhEr5gw"
      },
      "source": [
        "device='cuda'\n",
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 128\n",
        "DEC_EMB_DIM = 128\n",
        "ENC_HID_DIM = 256\n",
        "DEC_HID_DIM = 256\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzMi_jwNr5gw",
        "outputId": "55df7d01-53d1-4c00-ad0c-a62656012dfb"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(5923, 128)\n",
              "    (rnn): GRU(128, 256, bidirectional=True)\n",
              "    (fc): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=768, out_features=256, bias=True)\n",
              "      (v): Linear(in_features=256, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(7873, 128)\n",
              "    (rnn): GRU(640, 256)\n",
              "    (fc_out): Linear(in_features=896, out_features=7873, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj8GLLApr5gx"
      },
      "source": [
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src, src_len = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, src_len, trg)\n",
        "        \n",
        "        #trg = [trg_len, batch_size]\n",
        "        #output = [trg_len, batch_size, output_dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg_len - 1) * batch_size]\n",
        "        #output = [(trg_len - 1) * batch_size, output_dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src, src_len = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, src_len, trg, 0) #turn off teacher forcing\n",
        "            \n",
        "            #trg = [trg_len, batch_size]\n",
        "            #output = [trg_len, batch_size, output_dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg_len - 1) * batch_size]\n",
        "            #output = [(trg_len - 1) * batch_size, output_dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDrF4vPVtF_R"
      },
      "source": [
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB0bCvm5r5gy",
        "outputId": "a0726f61-3691-4494-e346-a1e4e4d54555"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        #torch.save(model.state_dict(), 'tut4-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {np.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {np.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 32s\n",
            "\tTrain Loss: 5.322 | Train PPL: 204.704\n",
            "\t Val. Loss: 5.052 |  Val. PPL: 156.298\n",
            "Epoch: 02 | Time: 0m 32s\n",
            "\tTrain Loss: 4.491 | Train PPL:  89.254\n",
            "\t Val. Loss: 4.825 |  Val. PPL: 124.550\n",
            "Epoch: 03 | Time: 0m 32s\n",
            "\tTrain Loss: 4.140 | Train PPL:  62.813\n",
            "\t Val. Loss: 4.633 |  Val. PPL: 102.808\n",
            "Epoch: 04 | Time: 0m 32s\n",
            "\tTrain Loss: 3.863 | Train PPL:  47.628\n",
            "\t Val. Loss: 4.441 |  Val. PPL:  84.875\n",
            "Epoch: 05 | Time: 0m 32s\n",
            "\tTrain Loss: 3.596 | Train PPL:  36.460\n",
            "\t Val. Loss: 4.221 |  Val. PPL:  68.073\n",
            "Epoch: 06 | Time: 0m 32s\n",
            "\tTrain Loss: 3.286 | Train PPL:  26.733\n",
            "\t Val. Loss: 3.981 |  Val. PPL:  53.548\n",
            "Epoch: 07 | Time: 0m 32s\n",
            "\tTrain Loss: 3.038 | Train PPL:  20.870\n",
            "\t Val. Loss: 3.774 |  Val. PPL:  43.565\n",
            "Epoch: 08 | Time: 0m 32s\n",
            "\tTrain Loss: 2.820 | Train PPL:  16.777\n",
            "\t Val. Loss: 3.638 |  Val. PPL:  38.024\n",
            "Epoch: 09 | Time: 0m 32s\n",
            "\tTrain Loss: 2.563 | Train PPL:  12.973\n",
            "\t Val. Loss: 3.480 |  Val. PPL:  32.451\n",
            "Epoch: 10 | Time: 0m 32s\n",
            "\tTrain Loss: 2.356 | Train PPL:  10.546\n",
            "\t Val. Loss: 3.419 |  Val. PPL:  30.542\n",
            "Epoch: 11 | Time: 0m 32s\n",
            "\tTrain Loss: 2.210 | Train PPL:   9.117\n",
            "\t Val. Loss: 3.350 |  Val. PPL:  28.493\n",
            "Epoch: 12 | Time: 0m 32s\n",
            "\tTrain Loss: 2.091 | Train PPL:   8.090\n",
            "\t Val. Loss: 3.295 |  Val. PPL:  26.977\n",
            "Epoch: 13 | Time: 0m 32s\n",
            "\tTrain Loss: 1.923 | Train PPL:   6.842\n",
            "\t Val. Loss: 3.379 |  Val. PPL:  29.345\n",
            "Epoch: 14 | Time: 0m 32s\n",
            "\tTrain Loss: 1.830 | Train PPL:   6.234\n",
            "\t Val. Loss: 3.325 |  Val. PPL:  27.797\n",
            "Epoch: 15 | Time: 0m 32s\n",
            "\tTrain Loss: 1.746 | Train PPL:   5.733\n",
            "\t Val. Loss: 3.347 |  Val. PPL:  28.419\n",
            "Epoch: 16 | Time: 0m 32s\n",
            "\tTrain Loss: 1.646 | Train PPL:   5.189\n",
            "\t Val. Loss: 3.316 |  Val. PPL:  27.537\n",
            "Epoch: 17 | Time: 0m 32s\n",
            "\tTrain Loss: 1.598 | Train PPL:   4.942\n",
            "\t Val. Loss: 3.316 |  Val. PPL:  27.538\n",
            "Epoch: 18 | Time: 0m 32s\n",
            "\tTrain Loss: 1.528 | Train PPL:   4.608\n",
            "\t Val. Loss: 3.384 |  Val. PPL:  29.499\n",
            "Epoch: 19 | Time: 0m 32s\n",
            "\tTrain Loss: 1.447 | Train PPL:   4.251\n",
            "\t Val. Loss: 3.392 |  Val. PPL:  29.733\n",
            "Epoch: 20 | Time: 0m 32s\n",
            "\tTrain Loss: 1.434 | Train PPL:   4.194\n",
            "\t Val. Loss: 3.345 |  Val. PPL:  28.352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDfP5io2zlQv"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "        \r\n",
        "    if isinstance(sentence, str):\r\n",
        "        nlp = spacy.load('de')\r\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\r\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\r\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\r\n",
        "    # src_tensor : [1, len(tokens)]\r\n",
        "\r\n",
        "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\r\n",
        "    with torch.no_grad():\r\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor, src_len)\r\n",
        "    # encoder_outputs : [src_len, 1, dec_hid_dim]\r\n",
        "    mask = model.create_mask(src_tensor)\r\n",
        "    # mask : [1, src_len]\r\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\r\n",
        "\r\n",
        "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\r\n",
        "    # attentions : [max_len,1,len(tokens)]\r\n",
        "    for i in range(max_len):\r\n",
        "\r\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\r\n",
        "                \r\n",
        "        with torch.no_grad():\r\n",
        "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\r\n",
        "\r\n",
        "        attentions[i] = attention\r\n",
        "            \r\n",
        "        pred_token = output.argmax(1).item()\r\n",
        "        \r\n",
        "        trg_indexes.append(pred_token)\r\n",
        "\r\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\r\n",
        "            break\r\n",
        "    \r\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\r\n",
        "    \r\n",
        "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak2EDnSer5gy"
      },
      "source": [
        "def display_attention(sentence, translation, attention):\r\n",
        "    \r\n",
        "    fig = plt.figure(figsize=(10,10))\r\n",
        "    ax = fig.add_subplot(111)\r\n",
        "    \r\n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\r\n",
        "    \r\n",
        "    cax = ax.matshow(attention, cmap='bone')\r\n",
        "   \r\n",
        "    ax.tick_params(labelsize=15)\r\n",
        "    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \r\n",
        "                       rotation=45)\r\n",
        "    ax.set_yticklabels(['']+translation)\r\n",
        "\r\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "    plt.show()\r\n",
        "    plt.close()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTeZJkLZzjb9",
        "outputId": "c27bff07-9529-4b92-ac0c-05bfc8c22eb7"
      },
      "source": [
        "example_idx = 12\r\n",
        "\r\n",
        "src = vars(valid_data.examples[example_idx])['src']\r\n",
        "trg = vars(valid_data.examples[example_idx])['trg']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'trg = {trg}')\r\n",
        "\r\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "\r\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['three', 'young', 'children', 'stand', 'around', 'a', 'blue', 'and', 'white', 'barrel', '.']\n",
            "trg = ['drei', 'kleine', 'kinder', 'stehen', 'um', 'ein', 'blau', '-', 'weißes', 'fass', 'herum', '.']\n",
            "predicted trg = ['drei', 'kleine', 'kinder', 'stehen', 'um', 'einen', 'blau', '-', 'weißen', 'und', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "-waxVqKDzppz",
        "outputId": "d46f6b97-96df-4543-83ba-3bd257b4cf3b"
      },
      "source": [
        "display_attention(src, translation, attention)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0KCsM3b1Pob"
      },
      "source": [
        "\r\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len=50):\r\n",
        "  trgs=[]\r\n",
        "  pred_trgs=[]\r\n",
        "\r\n",
        "  for d in data:\r\n",
        "    src = vars(d)['src']\r\n",
        "    trg = vars(d)['trg']\r\n",
        "\r\n",
        "    pred_trg, _ = translate_sentence(src, src_field, trg_field, model, 'cuda')\r\n",
        "\r\n",
        "    pred_trg = pred_trg[:-1]\r\n",
        "    pred_trgs.append(pred_trg)\r\n",
        "    trgs.append([trg])\r\n",
        "\r\n",
        "  return bleu_score(pred_trgs, trgs)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHEObKRx-iPc",
        "outputId": "2564cdcf-1b3e-4b40-e542-e7be1f689f7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\r\n",
        "print(f'bleu_score : {bleu_score * 100}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bleu_score : 26.78120570588986\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}